<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://shelvia-w.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://shelvia-w.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-03-19T18:33:07+00:00</updated><id>https://shelvia-w.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Sakana‚Äôs AI Scientist-Generated Research Papers Reviewed at ICLR 2025 Workshop</title><link href="https://shelvia-w.github.io/blog/2025/sakana_ai/" rel="alternate" type="text/html" title="Sakana‚Äôs AI Scientist-Generated Research Papers Reviewed at ICLR 2025 Workshop"/><published>2025-03-14T00:00:00+00:00</published><updated>2025-03-14T00:00:00+00:00</updated><id>https://shelvia-w.github.io/blog/2025/sakana_ai</id><content type="html" xml:base="https://shelvia-w.github.io/blog/2025/sakana_ai/"><![CDATA[<h3 id="sakana-ai">Sakana AI</h3> <p>I first heard about Sakana AI from a friend a week or two ago, and their <a href="https://sakana.ai/ai-scientist/">AI Scientist</a> immediately caught my attention. This AI agent isn‚Äôt just another research assistant‚Äîit generates novel ideas, writes code, runs experiments, visualizes results, and even composes full scientific papers, complete with a simulated review process for evaluation. After briefly reading the AI Scientist paper, I was intrigued by its potential and, since it‚Äôs open-source, I‚Äôm already thinking about how to implement it in my own field. The cost of generating these papers is surprisingly low‚Äîaround $15 per paper. Using just a single 8x NVIDIA H100 machine, they generated hundreds of papers in a week ‚Äî something that would have definitely made my supervisor very happy if I could do the same!</p> <h3 id="ai-generated-paper">AI-Generated Paper</h3> <p><a href="https://sakana.ai/ai-scientist-first-publication/">The 3 papers submitted to the ICLR 2025 workshop were generated by The AI Scientist-v2</a>, which was an improved version of the original AI Scientist, although the full details on the new model have yet to be released. The ICLR workshop name is ‚ÄúI Can‚Äôt Believe It‚Äôs Not Better: Challenges in Applied Deep Learning‚Äù. I think this is an interesting workshop which focuses on the challenges and failure modes of deep learning models. Of course, the organizers are fully aware that the paper was AI generated as Sakana AI has previously seeked permission to ‚Äútest‚Äù this experiment. The reviewers were only told that they might be reviewing AI generated papers (3 out of 43 papers) but were not told which ones. One of the papers, titled ‚ÄúCompositional Regularization: Unexpected Obstacles in Enhancing Neural Network Generalization‚Äù, received a score of 6.33 which is above the acceptance threshold. Nevertheless, the paper was eventually withdrawn after the reviewing process as it‚Äôs still unclear if AI-generated papers should be accepted at these venues. They also noted that none of the three papers met the threshold for acceptance in the ICLR main conference track. An interesting idea being brought up is using the AI Scientist to automate the reproducibility of existing papers instead of just generating new ones. Reproducibility is super important, but still pretty lacking in the research community, so this could actually be a game-changer. Also,looks like there‚Äôs another AI-generated paper accepted at the Tiny Papers workshop track at ICLR, this time from an AI agent called <a href="https://www.autoscience.ai/blog/meet-carl-the-first-ai-system-to-produce-academically-peer-reviewed-research">Carl</a>. Unlike Sakana‚Äôs AI Scientist, though, this one still had some human intervention.</p> <h3 id="some-issues-with-ai-scientist-generated-paper">Some Issues with AI Scientist-Generated Paper</h3> <ul> <li>Experiment details can sometimes be incorrect.</li> <li>Related work is incomplete and overly general.</li> <li>Cites incorrect references.</li> <li>Lacks precision in technical mathematical details.</li> <li>Figure captions can be inaccurate.</li> <li>Claims are not always clearly supported by the presented evidence and often lack further explanation.</li> <li>Has a tendency to overclaim.</li> </ul> <h3 id="questions-to-ponder">Questions to Ponder</h3> <ol> <li>Should AI-generated papers be submitted to the same venues as human-written ones, or do they need a separate category?</li> <li>If reviewers can‚Äôt distinguish between AI-generated and human-written papers, does it really matter how they were created?</li> <li>Are AI-generated papers just combining existing ideas, or can they truly create something novel?</li> </ol> <h3 id="references">References</h3> <ul> <li><a href="https://sakana.ai/ai-scientist/">The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery</a></li> <li><a href="https://sakana.ai/ai-scientist-first-publication/">The AI Scientist Generates its First Peer-Reviewed Scientific Publication</a></li> <li><a href="https://www.autoscience.ai/blog/meet-carl-the-first-ai-system-to-produce-academically-peer-reviewed-research">Meet Carl: The First AI System To Produce Academically Peer-Reviewed Research</a></li> <li><a href="https://github.com/SakanaAI/AI-Scientist-ICLR2025-Workshop-Experiment/blob/master/compositional-regularization/annotated_paper.pdf">Compositional Regularization: Unexpected Obstacles in Enhancing Neural Network Generalization</a></li> </ul>]]></content><author><name></name></author><category term="news,"/><category term="paper"/><category term="sakana_ai"/><summary type="html"><![CDATA[ü§î Can AI truly conduct its own research and write a full paper?]]></summary></entry><entry><title type="html">Transformers Can Work Without Normalization Layer?</title><link href="https://shelvia-w.github.io/blog/2025/dynamic_tanh/" rel="alternate" type="text/html" title="Transformers Can Work Without Normalization Layer?"/><published>2025-03-14T00:00:00+00:00</published><updated>2025-03-14T00:00:00+00:00</updated><id>https://shelvia-w.github.io/blog/2025/dynamic_tanh</id><content type="html" xml:base="https://shelvia-w.github.io/blog/2025/dynamic_tanh/"><![CDATA[<h3 id="dynamic-tanh">Dynamic Tanh</h3> <p>Last week, a friend shared an interesting paper with me from LeCun‚Äôs group, ‚Äú<a href="https://arxiv.org/pdf/2503.10622">Transformers without Normalization</a>,‚Äù where they introduced Dynamic Tanh (DyT) as a replacement for layer normalization in Transformers. Instead of using a normalization layer, they propose a simple element-wise operation:</p> \[DyT(x)=\tanh(\alpha x)\] <p>Their motivation? While researchers have been busy tweaking various parts of the Transformer architecture, the normalization layer has remained largely untouched. This raises an intriguing question: Is layer normalization truly essential for Transformers to perform well?</p> <h3 id="layer-normalization">Layer Normalization</h3> <p>Transformers typically rely on layer normalization (LN), which normalizes each token individually across its features, without considering other tokens or batch samples. LN is usually applied before self-attention and feed-forward layers. In the paper, they plotted the input-output curve of the LN layer (before the affine transformation) and noticed an interesting trend:</p> <ul> <li>In earlier layers, the relationship is mostly linear.</li> <li>In deeper layers, the curve starts resembling a tanh function.</li> </ul> <p>This observation aligns with insights from <a href="https://arxiv.org/pdf/2406.01255">several papers</a> exploring why normalization techniques work so well - definitely something I should dive deeper into!</p> <h3 id="results">Results</h3> <p>They found that swapping LN with DyT in Transformers resulted in a similar loss curve and comparable performance (slightly better in some cases). However, this doesn‚Äôt hold when replacing batch normalization with DyT in traditional architectures like ResNets, suggesting that the role of normalization might differ across model types.</p> <h3 id="questions-to-ponder">Questions to Ponder</h3> <ul> <li>Why is the suppression of extreme values or the non-linearity component crucial?</li> <li>Can we find an alternative function for batch normalization in classic networks that achieves similar results?</li> </ul> <h3 id="references">References</h3> <ul> <li><a href="https://arxiv.org/pdf/2503.10622">Transformers without Normalization</a></li> <li><a href="https://arxiv.org/pdf/2406.01255">On the Nonlinearity of Layer Normalization</a></li> </ul>]]></content><author><name></name></author><category term="paper"/><category term="regularization"/><summary type="html"><![CDATA[ü§î Yann LeCun's group introduced an alternative called Dynamic Tanh (DyT).]]></summary></entry></feed>