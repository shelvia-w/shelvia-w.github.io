<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://shelvia-w.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://shelvia-w.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-03-24T07:28:16+00:00</updated><id>https://shelvia-w.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html"></title><link href="https://shelvia-w.github.io/blog/2025/2025-03-24-news/" rel="alternate" type="text/html" title=""/><published>2025-03-24T07:28:16+00:00</published><updated>2025-03-24T07:28:16+00:00</updated><id>https://shelvia-w.github.io/blog/2025/2025-03-24-news</id><content type="html" xml:base="https://shelvia-w.github.io/blog/2025/2025-03-24-news/"><![CDATA[<h3 id="meta">Meta</h3> <p>Llama models are being used to:</p> <ul> <li><a href="https://jobsearchgenius.ai/">build an AI career coach to improve job search outcomes</a></li> <li>build a tourism app to learn about local history and culture</li> <li><a href="https://fynopsis.ai/">facilitate more efficient and accurate deals in the mergers and acquisitions (M&amp;A) space</a> From what I gathered, some prefer open-source models due to cost efficiency (fixed cost instead of paying per API call), data security and privacy (as the model can be fine-tuned locally), and a large developer community (making it easier to find solutions to problems). I am honestly very keen on trying them out as well.</li> </ul> <h3 id="google-deepmind">Google DeepMind</h3> <p>Google DeepMind introduced <a href="https://deepmind.google/technologies/gemini-robotics/">two new robotics AI models</a>, based on Gemini 2.0: Gemini Robotics (advanced vision-language-action (VLA) model) and Gemini Robotics-ER (advanced spatial understanding). They have released a <a href="https://storage.googleapis.com/deepmind-media/gemini-robotics/gemini_robotics_report.pdf">Tech Report</a> for Gemini Robotics as well as a <a href="https://asimov-benchmark.github.io/">new ASIMOV dataset</a> for evaluating and improving semantic safety in these robotic models. It’s a fun read if you’re into robotics!</p> <h3 id="openai">OpenAI</h3> <p>Researchers at the MIT Media Lab and OpenAI conducted a series of studies to understand how AI use that involves emotional engagement (they called it “affective use”) can impact users’ well-being. They carried out two studies: <a href="(https://www.media.mit.edu/publications/investigating-affective-use-and-emotional-well-being-on-chatgpt/)">an observational study</a> to analyze real-world on-platform usage patterns, and <a href="https://www.media.mit.edu/publications/how-ai-and-human-behaviors-shape-psychosocial-effects-of-chatbot-use-a-longitudinal-controlled-study/">a controlled interventional study</a> to understand the impacts on users. I’ve always been fascinated by psychology and behavioral sciences, so this study truly captivates me!</p> <h3 id="microsoft">Microsoft</h3> <p>Microsoft released a playbook, <a href="https://cdn-dynmedia-1.microsoft.com/is/content/microsoftcorp/microsoft/msc/documents/presentations/CSR/Accelerating-Sustainability-with-AI-2025.pdf">Accelerating sustainability with AI: Innovations for a better future</a>, outlining 5 ways to advance sustainability. I think it’s an interesting read for anyone interested in integrating AI into their business.</p> <h3 id="nvidia">NVIDIA</h3> <p>NVIDIA released <a href="https://huggingface.co/collections/nvidia/physical-ai-67c643edbb024053dcbcd6d8">Open Physical AI Dataset</a> (available on Hugging Face) for robotics and autonomous vehicle development. This dataset will continue to grow over time and will include both real-world and synthetic data. NVIDIA also will be using this dataset to train, test and validate physical AI for the <a href="https://nvidianews.nvidia.com/news/nvidia-announces-major-release-of-cosmos-world-foundation-models-and-physical-ai-data-tools">NVIDIA Cosmos</a> world model development platform, the <a href="https://www.nvidia.com/en-us/self-driving-cars/in-vehicle-computing/">NVIDIA DRIVE AV</a> software stack, the <a href="https://www.nvidia.com/en-us/industries/robotics/">NVIDIA Isaac</a> AI robot development platform and the <a href="https://www.nvidia.com/en-us/autonomous-machines/intelligent-video-analytics-platform/">NVIDIA Metropolis</a> application framework for smart cities. I’d love to dive deeper into each one of them, they sound extremely fascinating!</p> <h3 id="ibm">IBM</h3> <p>IBM released <a href="https://beeai.dev/">Bee AI</a> which is an open platform to run popular open-source AI agents from different frameworks. It can also be used to build specialized agents and be configured to work alone or with AI teammates. They also introduced <a href="https://docs.beeai.dev/acp/alpha/introduction">agent communication protocol</a> (ACP) to standardize how agents talk to each other. This is a step ahead of Anthropic’s <a href="https://modelcontextprotocol.io/introduction">model context protocol</a> (MCP) that standardizes how agents connect to tools and data to interact with and accomplish tasks in the real world. I think such protocol is important when developing multiagent systems, which are likely the next big advancement.</p> <h3 id="anthropic">Anthropic</h3> <p>Anthropic released a paper: <a href="https://assets.anthropic.com/m/317564659027fb33/original/Auditing-Language-Models-for-Hidden-Objectives.pdf">Auditing Language Models for Hidden Objectives</a>. In the paper, they studied the feasibilit of conducting alignment audits which are systematic investigations into whether models are pursuing hidden objectives. The objective is to uncover whether some AI systems that appear well-behaved actually harbor secret motives that are potentially misaligned with our intent. This is definitely something that I’ll read up more in detail as I’m very much into AI safety!</p> <h3 id="references">References</h3> <ul> <li><a href="https://ai.meta.com/blog/built-with-llama-writesea-fynopsis-srimoyee-mukhopadhyay-united-states-economy/">Our open source Llama models are helping to spur economic growth in the US</a></li> <li><a href="https://deepmind.google/discover/blog/gemini-robotics-brings-ai-into-the-physical-world/">Gemini Robotics brings AI into the physical world</a></li> <li><a href="https://openai.com/index/affective-use-study/">Early methods for studying affective use and emotional well-being on ChatGPT</a></li> <li><a href="https://www.microsoft.com/en-us/microsoft-cloud/blog/2025/03/18/harnessing-ai-for-resilience-efficiency-and-sustainability/">Harnessing AI for resilience, efficiency, and sustainability</a></li> <li><a href="https://blogs.nvidia.com/blog/open-physical-ai-dataset/">NVIDIA Unveils Open Physical AI Dataset to Advance Robotics and Autonomous Vehicle Development</a></li> <li><a href="https://research.ibm.com/blog/multiagent-bee-ai">BeeAI now has multiple agents, and a standardized way for them to talk</a></li> <li><a href="https://www.anthropic.com/research/auditing-hidden-objectives">Auditing language models for hidden objectives</a></li> </ul>]]></content><author><name></name></author></entry><entry><title type="html">Transformers Can Work Without Normalization Layer?</title><link href="https://shelvia-w.github.io/blog/2025/dynamic_tanh/" rel="alternate" type="text/html" title="Transformers Can Work Without Normalization Layer?"/><published>2025-03-19T00:00:00+00:00</published><updated>2025-03-19T00:00:00+00:00</updated><id>https://shelvia-w.github.io/blog/2025/dynamic_tanh</id><content type="html" xml:base="https://shelvia-w.github.io/blog/2025/dynamic_tanh/"><![CDATA[<h3 id="dynamic-tanh">Dynamic Tanh</h3> <p>Last week, a friend shared an interesting paper with me from LeCun’s group, “<a href="https://arxiv.org/pdf/2503.10622">Transformers without Normalization</a>,” where they introduced Dynamic Tanh (DyT) as a replacement for layer normalization in Transformers. Instead of using a normalization layer, they propose a simple element-wise operation:</p> \[DyT(x)=\tanh(\alpha x)\] <p>Their motivation? While researchers have been busy tweaking various parts of the Transformer architecture, the normalization layer has remained largely untouched. This raises an intriguing question: Is layer normalization truly essential for Transformers to perform well?</p> <h3 id="layer-normalization">Layer Normalization</h3> <p>Transformers typically rely on layer normalization (LN), which normalizes each token individually across its features, without considering other tokens or batch samples. LN is usually applied before self-attention and feed-forward layers. In the paper, they plotted the input-output curve of the LN layer (before the affine transformation) and noticed an interesting trend:</p> <ul> <li>In earlier layers, the relationship is mostly linear.</li> <li>In deeper layers, the curve starts resembling a tanh function.</li> </ul> <p>This observation aligns with insights from <a href="https://arxiv.org/pdf/2406.01255">several papers</a> exploring why normalization techniques work so well - definitely something I should dive deeper into!</p> <h3 id="results">Results</h3> <p>They found that swapping LN with DyT in Transformers resulted in a similar loss curve and comparable performance (slightly better in some cases). However, this doesn’t hold when replacing batch normalization with DyT in traditional architectures like ResNets, suggesting that the role of normalization might differ across model types.</p> <h3 id="questions-to-ponder">Questions to Ponder</h3> <ul> <li>Why is the suppression of extreme values or the non-linearity component crucial?</li> <li>Can we find an alternative function for batch normalization in classic networks that achieves similar results?</li> </ul> <h3 id="references">References</h3> <ul> <li><a href="https://arxiv.org/pdf/2503.10622">Transformers without Normalization</a></li> <li><a href="https://arxiv.org/pdf/2406.01255">On the Nonlinearity of Layer Normalization</a></li> </ul>]]></content><author><name></name></author><category term="paper"/><category term="regularization"/><summary type="html"><![CDATA[🤔 Yann LeCun's group introduced an alternative called Dynamic Tanh (DyT).]]></summary></entry><entry><title type="html">Sakana’s AI Scientist-Generated Research Papers Reviewed at ICLR 2025 Workshop</title><link href="https://shelvia-w.github.io/blog/2025/sakana_ai/" rel="alternate" type="text/html" title="Sakana’s AI Scientist-Generated Research Papers Reviewed at ICLR 2025 Workshop"/><published>2025-03-14T00:00:00+00:00</published><updated>2025-03-14T00:00:00+00:00</updated><id>https://shelvia-w.github.io/blog/2025/sakana_ai</id><content type="html" xml:base="https://shelvia-w.github.io/blog/2025/sakana_ai/"><![CDATA[<h3 id="sakana-ai">Sakana AI</h3> <p>I first heard about Sakana AI from a friend a week or two ago, and their <a href="https://sakana.ai/ai-scientist/">AI Scientist</a> immediately caught my attention. This AI agent isn’t just another research assistant—it generates novel ideas, writes code, runs experiments, visualizes results, and even composes full scientific papers, complete with a simulated review process for evaluation. After briefly reading the AI Scientist paper, I was intrigued by its potential and, since it’s open-source, I’m already thinking about how to implement it in my own field. The cost of generating these papers is surprisingly low—around $15 per paper. Using just a single 8x NVIDIA H100 machine, they generated hundreds of papers in a week — something that would have definitely made my supervisor very happy if I could do the same!</p> <h3 id="ai-generated-paper">AI-Generated Paper</h3> <p><a href="https://sakana.ai/ai-scientist-first-publication/">The 3 papers submitted to the ICLR 2025 workshop were generated by The AI Scientist-v2</a>, which was an improved version of the original AI Scientist, although the full details on the new model have yet to be released. The ICLR workshop name is “I Can’t Believe It’s Not Better: Challenges in Applied Deep Learning”. I think this is an interesting workshop which focuses on the challenges and failure modes of deep learning models. Of course, the organizers are fully aware that the paper was AI generated as Sakana AI has previously seeked permission to “test” this experiment. The reviewers were only told that they might be reviewing AI generated papers (3 out of 43 papers) but were not told which ones. One of the papers, titled “Compositional Regularization: Unexpected Obstacles in Enhancing Neural Network Generalization”, received a score of 6.33 which is above the acceptance threshold. Nevertheless, the paper was eventually withdrawn after the reviewing process as it’s still unclear if AI-generated papers should be accepted at these venues. They also noted that none of the three papers met the threshold for acceptance in the ICLR main conference track. An interesting idea being brought up is using the AI Scientist to automate the reproducibility of existing papers instead of just generating new ones. Reproducibility is super important, but still pretty lacking in the research community, so this could actually be a game-changer. Also,looks like there’s another AI-generated paper accepted at the Tiny Papers workshop track at ICLR, this time from an AI agent called <a href="https://www.autoscience.ai/blog/meet-carl-the-first-ai-system-to-produce-academically-peer-reviewed-research">Carl</a>. Unlike Sakana’s AI Scientist, though, this one still had some human intervention.</p> <h3 id="some-issues-with-ai-scientist-generated-paper">Some Issues with AI Scientist-Generated Paper</h3> <ul> <li>Experiment details can sometimes be incorrect.</li> <li>Related work is incomplete and overly general.</li> <li>Cites incorrect references.</li> <li>Lacks precision in technical mathematical details.</li> <li>Figure captions can be inaccurate.</li> <li>Claims are not always clearly supported by the presented evidence and often lack further explanation.</li> <li>Has a tendency to overclaim.</li> </ul> <h3 id="questions-to-ponder">Questions to Ponder</h3> <ol> <li>Should AI-generated papers be submitted to the same venues as human-written ones, or do they need a separate category?</li> <li>If reviewers can’t distinguish between AI-generated and human-written papers, does it really matter how they were created?</li> <li>Are AI-generated papers just combining existing ideas, or can they truly create something novel?</li> </ol> <h3 id="references">References</h3> <ul> <li><a href="https://sakana.ai/ai-scientist/">The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery</a></li> <li><a href="https://sakana.ai/ai-scientist-first-publication/">The AI Scientist Generates its First Peer-Reviewed Scientific Publication</a></li> <li><a href="https://www.autoscience.ai/blog/meet-carl-the-first-ai-system-to-produce-academically-peer-reviewed-research">Meet Carl: The First AI System To Produce Academically Peer-Reviewed Research</a></li> <li><a href="https://github.com/SakanaAI/AI-Scientist-ICLR2025-Workshop-Experiment/blob/master/compositional-regularization/annotated_paper.pdf">Compositional Regularization: Unexpected Obstacles in Enhancing Neural Network Generalization</a></li> </ul>]]></content><author><name></name></author><category term="news,"/><category term="paper"/><category term="sakana_ai"/><summary type="html"><![CDATA[🤔 Can AI truly conduct its own research and write a full paper?]]></summary></entry></feed>