<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <h3 id="meta">Meta</h3> <p>Llama models are being used to:</p> <ul> <li><a href="https://jobsearchgenius.ai/" rel="external nofollow noopener" target="_blank">build an AI career coach to improve job search outcomes</a></li> <li>build a tourism app to learn about local history and culture</li> <li> <a href="https://fynopsis.ai/" rel="external nofollow noopener" target="_blank">facilitate more efficient and accurate deals in the mergers and acquisitions (M&amp;A) space</a> From what I gathered, some prefer open-source models due to cost efficiency (fixed cost instead of paying per API call), data security and privacy (as the model can be fine-tuned locally), and a large developer community (making it easier to find solutions to problems). I am honestly very keen on trying them out as well.</li> </ul> <h3 id="google-deepmind">Google DeepMind</h3> <p>Google DeepMind introduced <a href="https://deepmind.google/technologies/gemini-robotics/" rel="external nofollow noopener" target="_blank">two new robotics AI models</a>, based on Gemini 2.0: Gemini Robotics (advanced vision-language-action (VLA) model) and Gemini Robotics-ER (advanced spatial understanding). They have released a <a href="https://storage.googleapis.com/deepmind-media/gemini-robotics/gemini_robotics_report.pdf" rel="external nofollow noopener" target="_blank">Tech Report</a> for Gemini Robotics as well as a <a href="https://asimov-benchmark.github.io/" rel="external nofollow noopener" target="_blank">new ASIMOV dataset</a> for evaluating and improving semantic safety in these robotic models. It’s a fun read if you’re into robotics!</p> <h3 id="openai">OpenAI</h3> <p>Researchers at the MIT Media Lab and OpenAI conducted a series of studies to understand how AI use that involves emotional engagement (they called it “affective use”) can impact users’ well-being. They carried out two studies: <a href="(https://www.media.mit.edu/publications/investigating-affective-use-and-emotional-well-being-on-chatgpt/)">an observational study</a> to analyze real-world on-platform usage patterns, and <a href="https://www.media.mit.edu/publications/how-ai-and-human-behaviors-shape-psychosocial-effects-of-chatbot-use-a-longitudinal-controlled-study/" rel="external nofollow noopener" target="_blank">a controlled interventional study</a> to understand the impacts on users. I’ve always been fascinated by psychology and behavioral sciences, so this study truly captivates me!</p> <h3 id="microsoft">Microsoft</h3> <p>Microsoft released a playbook, <a href="https://cdn-dynmedia-1.microsoft.com/is/content/microsoftcorp/microsoft/msc/documents/presentations/CSR/Accelerating-Sustainability-with-AI-2025.pdf" rel="external nofollow noopener" target="_blank">Accelerating sustainability with AI: Innovations for a better future</a>, outlining 5 ways to advance sustainability. I think it’s an interesting read for anyone interested in integrating AI into their business.</p> <h3 id="nvidia">NVIDIA</h3> <p>NVIDIA released <a href="https://huggingface.co/collections/nvidia/physical-ai-67c643edbb024053dcbcd6d8" rel="external nofollow noopener" target="_blank">Open Physical AI Dataset</a> (available on Hugging Face) for robotics and autonomous vehicle development. This dataset will continue to grow over time and will include both real-world and synthetic data. NVIDIA also will be using this dataset to train, test and validate physical AI for the <a href="https://nvidianews.nvidia.com/news/nvidia-announces-major-release-of-cosmos-world-foundation-models-and-physical-ai-data-tools" rel="external nofollow noopener" target="_blank">NVIDIA Cosmos</a> world model development platform, the <a href="https://www.nvidia.com/en-us/self-driving-cars/in-vehicle-computing/" rel="external nofollow noopener" target="_blank">NVIDIA DRIVE AV</a> software stack, the <a href="https://www.nvidia.com/en-us/industries/robotics/" rel="external nofollow noopener" target="_blank">NVIDIA Isaac</a> AI robot development platform and the <a href="https://www.nvidia.com/en-us/autonomous-machines/intelligent-video-analytics-platform/" rel="external nofollow noopener" target="_blank">NVIDIA Metropolis</a> application framework for smart cities. I’d love to dive deeper into each one of them, they sound extremely fascinating!</p> <h3 id="ibm">IBM</h3> <p>IBM released <a href="https://beeai.dev/" rel="external nofollow noopener" target="_blank">Bee AI</a> which is an open platform to run popular open-source AI agents from different frameworks. It can also be used to build specialized agents and be configured to work alone or with AI teammates. They also introduced <a href="https://docs.beeai.dev/acp/alpha/introduction" rel="external nofollow noopener" target="_blank">agent communication protocol</a> (ACP) to standardize how agents talk to each other. This is a step ahead of Anthropic’s <a href="https://modelcontextprotocol.io/introduction" rel="external nofollow noopener" target="_blank">model context protocol</a> (MCP) that standardizes how agents connect to tools and data to interact with and accomplish tasks in the real world. I think such protocol is important when developing multiagent systems, which are likely the next big advancement.</p> <h3 id="anthropic">Anthropic</h3> <p>Anthropic released a paper: <a href="https://assets.anthropic.com/m/317564659027fb33/original/Auditing-Language-Models-for-Hidden-Objectives.pdf" rel="external nofollow noopener" target="_blank">Auditing Language Models for Hidden Objectives</a>. In the paper, they studied the feasibilit of conducting alignment audits which are systematic investigations into whether models are pursuing hidden objectives. The objective is to uncover whether some AI systems that appear well-behaved actually harbor secret motives that are potentially misaligned with our intent. This is definitely something that I’ll read up more in detail as I’m very much into AI safety!</p> <h3 id="references">References</h3> <ul> <li><a href="https://ai.meta.com/blog/built-with-llama-writesea-fynopsis-srimoyee-mukhopadhyay-united-states-economy/" rel="external nofollow noopener" target="_blank">Our open source Llama models are helping to spur economic growth in the US</a></li> <li><a href="https://deepmind.google/discover/blog/gemini-robotics-brings-ai-into-the-physical-world/" rel="external nofollow noopener" target="_blank">Gemini Robotics brings AI into the physical world</a></li> <li><a href="https://openai.com/index/affective-use-study/" rel="external nofollow noopener" target="_blank">Early methods for studying affective use and emotional well-being on ChatGPT</a></li> <li><a href="https://www.microsoft.com/en-us/microsoft-cloud/blog/2025/03/18/harnessing-ai-for-resilience-efficiency-and-sustainability/" rel="external nofollow noopener" target="_blank">Harnessing AI for resilience, efficiency, and sustainability</a></li> <li><a href="https://blogs.nvidia.com/blog/open-physical-ai-dataset/" rel="external nofollow noopener" target="_blank">NVIDIA Unveils Open Physical AI Dataset to Advance Robotics and Autonomous Vehicle Development</a></li> <li><a href="https://research.ibm.com/blog/multiagent-bee-ai" rel="external nofollow noopener" target="_blank">BeeAI now has multiple agents, and a standardized way for them to talk</a></li> <li><a href="https://www.anthropic.com/research/auditing-hidden-objectives" rel="external nofollow noopener" target="_blank">Auditing language models for hidden objectives</a></li> </ul> </body></html>